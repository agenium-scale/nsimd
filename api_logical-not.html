<!-- Inspired from http://bettermotherfuckingwebsite.com/ -->

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title><code>nsimd</code> Documentation</title>
    <style type="text/css">
      body {
        /*margin:40px auto;*/
        margin:10px auto;
        /*max-width:650px;*/
        max-width:800px;
        /*line-height:1.6;*/
        line-height:1.4;
        /*font-size:18px;*/
        color:#444;
        padding:0 10px
      }
      h1,h2,h3 {
        line-height:1.2
      }
      table,th, td {
        border: 1px solid gray;
        border-collapse : collapse;
        padding: 1px 3px;
      }
    </style>
    <!-- https://www.mathjax.org/#gettingstarted -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-mml-chtml.js"></script>
  </head>
<body>

<center>
  <img src="img/logo.svg"><br>
  <br>
  <a href="index.html">Index</a> |
  <a href="quick_start.html">Quick Start</a> |
  <a href="tutorials.html">Tutorials</a> |
  <a href="faq.html">FAQ</a> |
  <a href="contribute.html">Contribute</a> |
  <a href="license.html">License</a> |
  <a href="api.html">API</a>
</center>
<h1>logical not</h1>
<h2>Description</h2>
<p>Returns the logical not of the argument. Defined over ùîπ.</p>
<h2>C base API (generic)</h2>
<pre class="c"><code>#define vnotl(a0, type)
#define vnotl_e(a0, type, simd_ext)</code></pre>
<h2>C++ base API (generic)</h2>
<pre class="c++"><code>template &lt;typename A0, typename T&gt; typename simd_traits&lt;T, NSIMD_SIMD&gt;::simd_vectorl notl(A0 a0, T);</code></pre>
<h2>C++ advanced API</h2>
<pre class="c++"><code>template &lt;typename T, typename SimdExt&gt; packl&lt;T, 1, SimdExt&gt; notl(packl&lt;T, 1, SimdExt&gt; const&amp; a0);
template &lt;typename T, int N, typename SimdExt&gt; packl&lt;T, N, SimdExt&gt; notl(packl&lt;T, N, SimdExt&gt; const&amp; a0);
template &lt;typename T, typename SimdExt&gt; packl&lt;T, 1, SimdExt&gt; operator!(packl&lt;T, 1, SimdExt&gt; const&amp; a0);
template &lt;typename T, int N, typename SimdExt&gt; packl&lt;T, N, SimdExt&gt; operator!(packl&lt;T, N, SimdExt&gt; const&amp; a0);</code></pre>
<h2>C base API (architecture specifics)</h2>
<h3>SSE2</h3>
<pre class="c"><code>nsimd_sse2_vlf64 nsimd_notl_sse2_f64(nsimd_sse2_vlf64 a0);
nsimd_sse2_vlf32 nsimd_notl_sse2_f32(nsimd_sse2_vlf32 a0);
nsimd_sse2_vlf16 nsimd_notl_sse2_f16(nsimd_sse2_vlf16 a0);
nsimd_sse2_vli64 nsimd_notl_sse2_i64(nsimd_sse2_vli64 a0);
nsimd_sse2_vli32 nsimd_notl_sse2_i32(nsimd_sse2_vli32 a0);
nsimd_sse2_vli16 nsimd_notl_sse2_i16(nsimd_sse2_vli16 a0);
nsimd_sse2_vli8 nsimd_notl_sse2_i8(nsimd_sse2_vli8 a0);
nsimd_sse2_vlu64 nsimd_notl_sse2_u64(nsimd_sse2_vlu64 a0);
nsimd_sse2_vlu32 nsimd_notl_sse2_u32(nsimd_sse2_vlu32 a0);
nsimd_sse2_vlu16 nsimd_notl_sse2_u16(nsimd_sse2_vlu16 a0);
nsimd_sse2_vlu8 nsimd_notl_sse2_u8(nsimd_sse2_vlu8 a0);</code></pre>
<h3>CPU</h3>
<pre class="c"><code>nsimd_cpu_vlf64 nsimd_notl_cpu_f64(nsimd_cpu_vlf64 a0);
nsimd_cpu_vlf32 nsimd_notl_cpu_f32(nsimd_cpu_vlf32 a0);
nsimd_cpu_vlf16 nsimd_notl_cpu_f16(nsimd_cpu_vlf16 a0);
nsimd_cpu_vli64 nsimd_notl_cpu_i64(nsimd_cpu_vli64 a0);
nsimd_cpu_vli32 nsimd_notl_cpu_i32(nsimd_cpu_vli32 a0);
nsimd_cpu_vli16 nsimd_notl_cpu_i16(nsimd_cpu_vli16 a0);
nsimd_cpu_vli8 nsimd_notl_cpu_i8(nsimd_cpu_vli8 a0);
nsimd_cpu_vlu64 nsimd_notl_cpu_u64(nsimd_cpu_vlu64 a0);
nsimd_cpu_vlu32 nsimd_notl_cpu_u32(nsimd_cpu_vlu32 a0);
nsimd_cpu_vlu16 nsimd_notl_cpu_u16(nsimd_cpu_vlu16 a0);
nsimd_cpu_vlu8 nsimd_notl_cpu_u8(nsimd_cpu_vlu8 a0);</code></pre>
<h3>AVX512_SKYLAKE</h3>
<pre class="c"><code>nsimd_avx512_skylake_vlf64 nsimd_notl_avx512_skylake_f64(nsimd_avx512_skylake_vlf64 a0);
nsimd_avx512_skylake_vlf32 nsimd_notl_avx512_skylake_f32(nsimd_avx512_skylake_vlf32 a0);
nsimd_avx512_skylake_vlf16 nsimd_notl_avx512_skylake_f16(nsimd_avx512_skylake_vlf16 a0);
nsimd_avx512_skylake_vli64 nsimd_notl_avx512_skylake_i64(nsimd_avx512_skylake_vli64 a0);
nsimd_avx512_skylake_vli32 nsimd_notl_avx512_skylake_i32(nsimd_avx512_skylake_vli32 a0);
nsimd_avx512_skylake_vli16 nsimd_notl_avx512_skylake_i16(nsimd_avx512_skylake_vli16 a0);
nsimd_avx512_skylake_vli8 nsimd_notl_avx512_skylake_i8(nsimd_avx512_skylake_vli8 a0);
nsimd_avx512_skylake_vlu64 nsimd_notl_avx512_skylake_u64(nsimd_avx512_skylake_vlu64 a0);
nsimd_avx512_skylake_vlu32 nsimd_notl_avx512_skylake_u32(nsimd_avx512_skylake_vlu32 a0);
nsimd_avx512_skylake_vlu16 nsimd_notl_avx512_skylake_u16(nsimd_avx512_skylake_vlu16 a0);
nsimd_avx512_skylake_vlu8 nsimd_notl_avx512_skylake_u8(nsimd_avx512_skylake_vlu8 a0);</code></pre>
<h3>AARCH64</h3>
<pre class="c"><code>nsimd_aarch64_vlf64 nsimd_notl_aarch64_f64(nsimd_aarch64_vlf64 a0);
nsimd_aarch64_vlf32 nsimd_notl_aarch64_f32(nsimd_aarch64_vlf32 a0);
nsimd_aarch64_vlf16 nsimd_notl_aarch64_f16(nsimd_aarch64_vlf16 a0);
nsimd_aarch64_vli64 nsimd_notl_aarch64_i64(nsimd_aarch64_vli64 a0);
nsimd_aarch64_vli32 nsimd_notl_aarch64_i32(nsimd_aarch64_vli32 a0);
nsimd_aarch64_vli16 nsimd_notl_aarch64_i16(nsimd_aarch64_vli16 a0);
nsimd_aarch64_vli8 nsimd_notl_aarch64_i8(nsimd_aarch64_vli8 a0);
nsimd_aarch64_vlu64 nsimd_notl_aarch64_u64(nsimd_aarch64_vlu64 a0);
nsimd_aarch64_vlu32 nsimd_notl_aarch64_u32(nsimd_aarch64_vlu32 a0);
nsimd_aarch64_vlu16 nsimd_notl_aarch64_u16(nsimd_aarch64_vlu16 a0);
nsimd_aarch64_vlu8 nsimd_notl_aarch64_u8(nsimd_aarch64_vlu8 a0);</code></pre>
<h3>NEON128</h3>
<pre class="c"><code>nsimd_neon128_vlf64 nsimd_notl_neon128_f64(nsimd_neon128_vlf64 a0);
nsimd_neon128_vlf32 nsimd_notl_neon128_f32(nsimd_neon128_vlf32 a0);
nsimd_neon128_vlf16 nsimd_notl_neon128_f16(nsimd_neon128_vlf16 a0);
nsimd_neon128_vli64 nsimd_notl_neon128_i64(nsimd_neon128_vli64 a0);
nsimd_neon128_vli32 nsimd_notl_neon128_i32(nsimd_neon128_vli32 a0);
nsimd_neon128_vli16 nsimd_notl_neon128_i16(nsimd_neon128_vli16 a0);
nsimd_neon128_vli8 nsimd_notl_neon128_i8(nsimd_neon128_vli8 a0);
nsimd_neon128_vlu64 nsimd_notl_neon128_u64(nsimd_neon128_vlu64 a0);
nsimd_neon128_vlu32 nsimd_notl_neon128_u32(nsimd_neon128_vlu32 a0);
nsimd_neon128_vlu16 nsimd_notl_neon128_u16(nsimd_neon128_vlu16 a0);
nsimd_neon128_vlu8 nsimd_notl_neon128_u8(nsimd_neon128_vlu8 a0);</code></pre>
<h3>SVE</h3>
<pre class="c"><code>nsimd_sve_vlf64 nsimd_notl_sve_f64(nsimd_sve_vlf64 a0);
nsimd_sve_vlf32 nsimd_notl_sve_f32(nsimd_sve_vlf32 a0);
nsimd_sve_vlf16 nsimd_notl_sve_f16(nsimd_sve_vlf16 a0);
nsimd_sve_vli64 nsimd_notl_sve_i64(nsimd_sve_vli64 a0);
nsimd_sve_vli32 nsimd_notl_sve_i32(nsimd_sve_vli32 a0);
nsimd_sve_vli16 nsimd_notl_sve_i16(nsimd_sve_vli16 a0);
nsimd_sve_vli8 nsimd_notl_sve_i8(nsimd_sve_vli8 a0);
nsimd_sve_vlu64 nsimd_notl_sve_u64(nsimd_sve_vlu64 a0);
nsimd_sve_vlu32 nsimd_notl_sve_u32(nsimd_sve_vlu32 a0);
nsimd_sve_vlu16 nsimd_notl_sve_u16(nsimd_sve_vlu16 a0);
nsimd_sve_vlu8 nsimd_notl_sve_u8(nsimd_sve_vlu8 a0);</code></pre>
<h3>AVX512_KNL</h3>
<pre class="c"><code>nsimd_avx512_knl_vlf64 nsimd_notl_avx512_knl_f64(nsimd_avx512_knl_vlf64 a0);
nsimd_avx512_knl_vlf32 nsimd_notl_avx512_knl_f32(nsimd_avx512_knl_vlf32 a0);
nsimd_avx512_knl_vlf16 nsimd_notl_avx512_knl_f16(nsimd_avx512_knl_vlf16 a0);
nsimd_avx512_knl_vli64 nsimd_notl_avx512_knl_i64(nsimd_avx512_knl_vli64 a0);
nsimd_avx512_knl_vli32 nsimd_notl_avx512_knl_i32(nsimd_avx512_knl_vli32 a0);
nsimd_avx512_knl_vli16 nsimd_notl_avx512_knl_i16(nsimd_avx512_knl_vli16 a0);
nsimd_avx512_knl_vli8 nsimd_notl_avx512_knl_i8(nsimd_avx512_knl_vli8 a0);
nsimd_avx512_knl_vlu64 nsimd_notl_avx512_knl_u64(nsimd_avx512_knl_vlu64 a0);
nsimd_avx512_knl_vlu32 nsimd_notl_avx512_knl_u32(nsimd_avx512_knl_vlu32 a0);
nsimd_avx512_knl_vlu16 nsimd_notl_avx512_knl_u16(nsimd_avx512_knl_vlu16 a0);
nsimd_avx512_knl_vlu8 nsimd_notl_avx512_knl_u8(nsimd_avx512_knl_vlu8 a0);</code></pre>
<h3>SSE42</h3>
<pre class="c"><code>nsimd_sse42_vlf64 nsimd_notl_sse42_f64(nsimd_sse42_vlf64 a0);
nsimd_sse42_vlf32 nsimd_notl_sse42_f32(nsimd_sse42_vlf32 a0);
nsimd_sse42_vlf16 nsimd_notl_sse42_f16(nsimd_sse42_vlf16 a0);
nsimd_sse42_vli64 nsimd_notl_sse42_i64(nsimd_sse42_vli64 a0);
nsimd_sse42_vli32 nsimd_notl_sse42_i32(nsimd_sse42_vli32 a0);
nsimd_sse42_vli16 nsimd_notl_sse42_i16(nsimd_sse42_vli16 a0);
nsimd_sse42_vli8 nsimd_notl_sse42_i8(nsimd_sse42_vli8 a0);
nsimd_sse42_vlu64 nsimd_notl_sse42_u64(nsimd_sse42_vlu64 a0);
nsimd_sse42_vlu32 nsimd_notl_sse42_u32(nsimd_sse42_vlu32 a0);
nsimd_sse42_vlu16 nsimd_notl_sse42_u16(nsimd_sse42_vlu16 a0);
nsimd_sse42_vlu8 nsimd_notl_sse42_u8(nsimd_sse42_vlu8 a0);</code></pre>
<h3>AVX2</h3>
<pre class="c"><code>nsimd_avx2_vlf64 nsimd_notl_avx2_f64(nsimd_avx2_vlf64 a0);
nsimd_avx2_vlf32 nsimd_notl_avx2_f32(nsimd_avx2_vlf32 a0);
nsimd_avx2_vlf16 nsimd_notl_avx2_f16(nsimd_avx2_vlf16 a0);
nsimd_avx2_vli64 nsimd_notl_avx2_i64(nsimd_avx2_vli64 a0);
nsimd_avx2_vli32 nsimd_notl_avx2_i32(nsimd_avx2_vli32 a0);
nsimd_avx2_vli16 nsimd_notl_avx2_i16(nsimd_avx2_vli16 a0);
nsimd_avx2_vli8 nsimd_notl_avx2_i8(nsimd_avx2_vli8 a0);
nsimd_avx2_vlu64 nsimd_notl_avx2_u64(nsimd_avx2_vlu64 a0);
nsimd_avx2_vlu32 nsimd_notl_avx2_u32(nsimd_avx2_vlu32 a0);
nsimd_avx2_vlu16 nsimd_notl_avx2_u16(nsimd_avx2_vlu16 a0);
nsimd_avx2_vlu8 nsimd_notl_avx2_u8(nsimd_avx2_vlu8 a0);</code></pre>
<h3>AVX</h3>
<pre class="c"><code>nsimd_avx_vlf64 nsimd_notl_avx_f64(nsimd_avx_vlf64 a0);
nsimd_avx_vlf32 nsimd_notl_avx_f32(nsimd_avx_vlf32 a0);
nsimd_avx_vlf16 nsimd_notl_avx_f16(nsimd_avx_vlf16 a0);
nsimd_avx_vli64 nsimd_notl_avx_i64(nsimd_avx_vli64 a0);
nsimd_avx_vli32 nsimd_notl_avx_i32(nsimd_avx_vli32 a0);
nsimd_avx_vli16 nsimd_notl_avx_i16(nsimd_avx_vli16 a0);
nsimd_avx_vli8 nsimd_notl_avx_i8(nsimd_avx_vli8 a0);
nsimd_avx_vlu64 nsimd_notl_avx_u64(nsimd_avx_vlu64 a0);
nsimd_avx_vlu32 nsimd_notl_avx_u32(nsimd_avx_vlu32 a0);
nsimd_avx_vlu16 nsimd_notl_avx_u16(nsimd_avx_vlu16 a0);
nsimd_avx_vlu8 nsimd_notl_avx_u8(nsimd_avx_vlu8 a0);</code></pre>
<h2>C++ base API (architecture specifics)</h2>
<h3>SSE2</h3>
<pre class="c"><code>nsimd_sse2_vlf64 notl(nsimd_sse2_vlf64 a0, f64, sse2);
nsimd_sse2_vlf32 notl(nsimd_sse2_vlf32 a0, f32, sse2);
nsimd_sse2_vlf16 notl(nsimd_sse2_vlf16 a0, f16, sse2);
nsimd_sse2_vli64 notl(nsimd_sse2_vli64 a0, i64, sse2);
nsimd_sse2_vli32 notl(nsimd_sse2_vli32 a0, i32, sse2);
nsimd_sse2_vli16 notl(nsimd_sse2_vli16 a0, i16, sse2);
nsimd_sse2_vli8 notl(nsimd_sse2_vli8 a0, i8, sse2);
nsimd_sse2_vlu64 notl(nsimd_sse2_vlu64 a0, u64, sse2);
nsimd_sse2_vlu32 notl(nsimd_sse2_vlu32 a0, u32, sse2);
nsimd_sse2_vlu16 notl(nsimd_sse2_vlu16 a0, u16, sse2);
nsimd_sse2_vlu8 notl(nsimd_sse2_vlu8 a0, u8, sse2);</code></pre>
<h3>CPU</h3>
<pre class="c"><code>nsimd_cpu_vlf64 notl(nsimd_cpu_vlf64 a0, f64, cpu);
nsimd_cpu_vlf32 notl(nsimd_cpu_vlf32 a0, f32, cpu);
nsimd_cpu_vlf16 notl(nsimd_cpu_vlf16 a0, f16, cpu);
nsimd_cpu_vli64 notl(nsimd_cpu_vli64 a0, i64, cpu);
nsimd_cpu_vli32 notl(nsimd_cpu_vli32 a0, i32, cpu);
nsimd_cpu_vli16 notl(nsimd_cpu_vli16 a0, i16, cpu);
nsimd_cpu_vli8 notl(nsimd_cpu_vli8 a0, i8, cpu);
nsimd_cpu_vlu64 notl(nsimd_cpu_vlu64 a0, u64, cpu);
nsimd_cpu_vlu32 notl(nsimd_cpu_vlu32 a0, u32, cpu);
nsimd_cpu_vlu16 notl(nsimd_cpu_vlu16 a0, u16, cpu);
nsimd_cpu_vlu8 notl(nsimd_cpu_vlu8 a0, u8, cpu);</code></pre>
<h3>AVX512_SKYLAKE</h3>
<pre class="c"><code>nsimd_avx512_skylake_vlf64 notl(nsimd_avx512_skylake_vlf64 a0, f64, avx512_skylake);
nsimd_avx512_skylake_vlf32 notl(nsimd_avx512_skylake_vlf32 a0, f32, avx512_skylake);
nsimd_avx512_skylake_vlf16 notl(nsimd_avx512_skylake_vlf16 a0, f16, avx512_skylake);
nsimd_avx512_skylake_vli64 notl(nsimd_avx512_skylake_vli64 a0, i64, avx512_skylake);
nsimd_avx512_skylake_vli32 notl(nsimd_avx512_skylake_vli32 a0, i32, avx512_skylake);
nsimd_avx512_skylake_vli16 notl(nsimd_avx512_skylake_vli16 a0, i16, avx512_skylake);
nsimd_avx512_skylake_vli8 notl(nsimd_avx512_skylake_vli8 a0, i8, avx512_skylake);
nsimd_avx512_skylake_vlu64 notl(nsimd_avx512_skylake_vlu64 a0, u64, avx512_skylake);
nsimd_avx512_skylake_vlu32 notl(nsimd_avx512_skylake_vlu32 a0, u32, avx512_skylake);
nsimd_avx512_skylake_vlu16 notl(nsimd_avx512_skylake_vlu16 a0, u16, avx512_skylake);
nsimd_avx512_skylake_vlu8 notl(nsimd_avx512_skylake_vlu8 a0, u8, avx512_skylake);</code></pre>
<h3>AARCH64</h3>
<pre class="c"><code>nsimd_aarch64_vlf64 notl(nsimd_aarch64_vlf64 a0, f64, aarch64);
nsimd_aarch64_vlf32 notl(nsimd_aarch64_vlf32 a0, f32, aarch64);
nsimd_aarch64_vlf16 notl(nsimd_aarch64_vlf16 a0, f16, aarch64);
nsimd_aarch64_vli64 notl(nsimd_aarch64_vli64 a0, i64, aarch64);
nsimd_aarch64_vli32 notl(nsimd_aarch64_vli32 a0, i32, aarch64);
nsimd_aarch64_vli16 notl(nsimd_aarch64_vli16 a0, i16, aarch64);
nsimd_aarch64_vli8 notl(nsimd_aarch64_vli8 a0, i8, aarch64);
nsimd_aarch64_vlu64 notl(nsimd_aarch64_vlu64 a0, u64, aarch64);
nsimd_aarch64_vlu32 notl(nsimd_aarch64_vlu32 a0, u32, aarch64);
nsimd_aarch64_vlu16 notl(nsimd_aarch64_vlu16 a0, u16, aarch64);
nsimd_aarch64_vlu8 notl(nsimd_aarch64_vlu8 a0, u8, aarch64);</code></pre>
<h3>NEON128</h3>
<pre class="c"><code>nsimd_neon128_vlf64 notl(nsimd_neon128_vlf64 a0, f64, neon128);
nsimd_neon128_vlf32 notl(nsimd_neon128_vlf32 a0, f32, neon128);
nsimd_neon128_vlf16 notl(nsimd_neon128_vlf16 a0, f16, neon128);
nsimd_neon128_vli64 notl(nsimd_neon128_vli64 a0, i64, neon128);
nsimd_neon128_vli32 notl(nsimd_neon128_vli32 a0, i32, neon128);
nsimd_neon128_vli16 notl(nsimd_neon128_vli16 a0, i16, neon128);
nsimd_neon128_vli8 notl(nsimd_neon128_vli8 a0, i8, neon128);
nsimd_neon128_vlu64 notl(nsimd_neon128_vlu64 a0, u64, neon128);
nsimd_neon128_vlu32 notl(nsimd_neon128_vlu32 a0, u32, neon128);
nsimd_neon128_vlu16 notl(nsimd_neon128_vlu16 a0, u16, neon128);
nsimd_neon128_vlu8 notl(nsimd_neon128_vlu8 a0, u8, neon128);</code></pre>
<h3>SVE</h3>
<pre class="c"><code>nsimd_sve_vlf64 notl(nsimd_sve_vlf64 a0, f64, sve);
nsimd_sve_vlf32 notl(nsimd_sve_vlf32 a0, f32, sve);
nsimd_sve_vlf16 notl(nsimd_sve_vlf16 a0, f16, sve);
nsimd_sve_vli64 notl(nsimd_sve_vli64 a0, i64, sve);
nsimd_sve_vli32 notl(nsimd_sve_vli32 a0, i32, sve);
nsimd_sve_vli16 notl(nsimd_sve_vli16 a0, i16, sve);
nsimd_sve_vli8 notl(nsimd_sve_vli8 a0, i8, sve);
nsimd_sve_vlu64 notl(nsimd_sve_vlu64 a0, u64, sve);
nsimd_sve_vlu32 notl(nsimd_sve_vlu32 a0, u32, sve);
nsimd_sve_vlu16 notl(nsimd_sve_vlu16 a0, u16, sve);
nsimd_sve_vlu8 notl(nsimd_sve_vlu8 a0, u8, sve);</code></pre>
<h3>AVX512_KNL</h3>
<pre class="c"><code>nsimd_avx512_knl_vlf64 notl(nsimd_avx512_knl_vlf64 a0, f64, avx512_knl);
nsimd_avx512_knl_vlf32 notl(nsimd_avx512_knl_vlf32 a0, f32, avx512_knl);
nsimd_avx512_knl_vlf16 notl(nsimd_avx512_knl_vlf16 a0, f16, avx512_knl);
nsimd_avx512_knl_vli64 notl(nsimd_avx512_knl_vli64 a0, i64, avx512_knl);
nsimd_avx512_knl_vli32 notl(nsimd_avx512_knl_vli32 a0, i32, avx512_knl);
nsimd_avx512_knl_vli16 notl(nsimd_avx512_knl_vli16 a0, i16, avx512_knl);
nsimd_avx512_knl_vli8 notl(nsimd_avx512_knl_vli8 a0, i8, avx512_knl);
nsimd_avx512_knl_vlu64 notl(nsimd_avx512_knl_vlu64 a0, u64, avx512_knl);
nsimd_avx512_knl_vlu32 notl(nsimd_avx512_knl_vlu32 a0, u32, avx512_knl);
nsimd_avx512_knl_vlu16 notl(nsimd_avx512_knl_vlu16 a0, u16, avx512_knl);
nsimd_avx512_knl_vlu8 notl(nsimd_avx512_knl_vlu8 a0, u8, avx512_knl);</code></pre>
<h3>SSE42</h3>
<pre class="c"><code>nsimd_sse42_vlf64 notl(nsimd_sse42_vlf64 a0, f64, sse42);
nsimd_sse42_vlf32 notl(nsimd_sse42_vlf32 a0, f32, sse42);
nsimd_sse42_vlf16 notl(nsimd_sse42_vlf16 a0, f16, sse42);
nsimd_sse42_vli64 notl(nsimd_sse42_vli64 a0, i64, sse42);
nsimd_sse42_vli32 notl(nsimd_sse42_vli32 a0, i32, sse42);
nsimd_sse42_vli16 notl(nsimd_sse42_vli16 a0, i16, sse42);
nsimd_sse42_vli8 notl(nsimd_sse42_vli8 a0, i8, sse42);
nsimd_sse42_vlu64 notl(nsimd_sse42_vlu64 a0, u64, sse42);
nsimd_sse42_vlu32 notl(nsimd_sse42_vlu32 a0, u32, sse42);
nsimd_sse42_vlu16 notl(nsimd_sse42_vlu16 a0, u16, sse42);
nsimd_sse42_vlu8 notl(nsimd_sse42_vlu8 a0, u8, sse42);</code></pre>
<h3>AVX2</h3>
<pre class="c"><code>nsimd_avx2_vlf64 notl(nsimd_avx2_vlf64 a0, f64, avx2);
nsimd_avx2_vlf32 notl(nsimd_avx2_vlf32 a0, f32, avx2);
nsimd_avx2_vlf16 notl(nsimd_avx2_vlf16 a0, f16, avx2);
nsimd_avx2_vli64 notl(nsimd_avx2_vli64 a0, i64, avx2);
nsimd_avx2_vli32 notl(nsimd_avx2_vli32 a0, i32, avx2);
nsimd_avx2_vli16 notl(nsimd_avx2_vli16 a0, i16, avx2);
nsimd_avx2_vli8 notl(nsimd_avx2_vli8 a0, i8, avx2);
nsimd_avx2_vlu64 notl(nsimd_avx2_vlu64 a0, u64, avx2);
nsimd_avx2_vlu32 notl(nsimd_avx2_vlu32 a0, u32, avx2);
nsimd_avx2_vlu16 notl(nsimd_avx2_vlu16 a0, u16, avx2);
nsimd_avx2_vlu8 notl(nsimd_avx2_vlu8 a0, u8, avx2);</code></pre>
<h3>AVX</h3>
<pre class="c"><code>nsimd_avx_vlf64 notl(nsimd_avx_vlf64 a0, f64, avx);
nsimd_avx_vlf32 notl(nsimd_avx_vlf32 a0, f32, avx);
nsimd_avx_vlf16 notl(nsimd_avx_vlf16 a0, f16, avx);
nsimd_avx_vli64 notl(nsimd_avx_vli64 a0, i64, avx);
nsimd_avx_vli32 notl(nsimd_avx_vli32 a0, i32, avx);
nsimd_avx_vli16 notl(nsimd_avx_vli16 a0, i16, avx);
nsimd_avx_vli8 notl(nsimd_avx_vli8 a0, i8, avx);
nsimd_avx_vlu64 notl(nsimd_avx_vlu64 a0, u64, avx);
nsimd_avx_vlu32 notl(nsimd_avx_vlu32 a0, u32, avx);
nsimd_avx_vlu16 notl(nsimd_avx_vlu16 a0, u16, avx);
nsimd_avx_vlu8 notl(nsimd_avx_vlu8 a0, u8, avx);</code></pre>
  </body>
</html>
