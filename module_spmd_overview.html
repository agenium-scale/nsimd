<!--

Copyright (c) 2021 Agenium Scale

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

-->

<!-- This file has been auto-generated -->

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NSIMD documentation</title>
    <style type="text/css">
      body {
        /*margin:40px auto;*/
        margin:10px auto;
        /*max-width:650px;*/
        max-width:800px;
        /*line-height:1.6;*/
        line-height:1.4;
        /*font-size:18px;*/
        color:#444;
        padding: 0 10px;
      }
      h1,h2,h3 {
        line-height: 1.2;
      }
      table {
        border-collapse: collapse;
        border: 0px solid gray;
        width: 100%;
      }
      th, td {
        border: 2px solid gray;
        padding: 0px 1em 0px 1em;
      }
    </style>
    <!-- https://www.mathjax.org/#gettingstarted -->
    <script src="assets/polyfill.min.js"></script>
    <script id="MathJax-script" async src="assets/tex-svg.js"></script>
    <!-- Highlight.js -->
    <link rel="stylesheet" href= "assets/highlight.js.default.min.css">
    <script src="assets/highlight.min.js"></script>
    <script src="assets/cpp.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </head>
<body>

<div style="text-align: center; margin-bottom: 1em;">
  <img src="img/logo.svg">
  <hr>
</div>
<div style="text-align: center; margin-bottom: 1em;">
  <b>NSIMD documentation</b>
</div>
<div style="text-align: center; margin-bottom: 1em;">
  <a href="index.html">Index</a> |
  <a href="tutorial.html">Tutorial</a> |
  <a href="faq.html">FAQ</a> |
  <a href="contribute.html">Contribute</a> |
  <a href="overview.html">API overview</a> |
  <a href="api.html">API reference</a> |
  <a href="wrapped_intrinsics.html">Wrapped intrinsics</a> |
  <a href="modules.html">Modules</a>
  <hr>
</div>
<div style="text-align: center; margin-bottom: 1em;">
<b>SPMD programming module documentation</b>
</div>
<div style="text-align: center; margin-bottom: 1em;">
<a href="module_spmd_overview.html">Overview</a> | <a href="module_spmd_api.html">API reference</a>
<hr>
</div>

<h1>Overview</h1>
<h2>What is SPMD?</h2>
<p>SPMD stands for <em>Single Program Multiple Data</em>. It is a programming paradigm.
It is used by NVIDIA CUDA. Its strengh lies in writing computation kernels.
Basically you concentrate your attention on the kernel itself and not on
how to run it. An example is worth more than a long speech, let&apos;s take vector
addition of <code>float</code>&apos;s.</p>
<pre class="c++"><code>spmd_kernel_1d(add, float *dst, float *a, float *b)
  k_store(dst, k_load(a) + k_load(b));
spmd_kernel_end</code></pre>
<p>It would be written as follows for CUDA (assuming that the vector lenghts are
multiples of block&apos;s sizes).</p>
<pre class="c++"><code>__global__ add(float *dst, float *a, float *b) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  dst[i] = a[i] + b[i];
}</code></pre>
<p>NSIMD&apos;s SPMD is a small DSL in standard C++98 that can be used to write
computation kernels for GPUs (NVIDIA&apos;s and AMD&apos;s) and any SIMD units supported
by NSIMD. On a more technical side, the DSL keywords are macros that:</p>
<ul>
<li><p>translates to C-ish keywords for GPUs and</p></li>
<li><p>use masks for CPUs as Intel ISPC (<a href="https://ispc.github.io/">https://ispc.github.io/</a>).</p></li>
</ul>
<p>The difference between NSIMD&apos;s SPMD is that a single code can be compiled
to target GPUs and CPUs whereas:</p>
<ul>
<li><p>NVIDIA CUDA only targets NVIDIA GPUs</p></li>
<li><p>AMD HIP only targets NVIDIA and AMD GPUs</p></li>
<li><p>INTEL ICP only targets Intel SIMD units and ARM NEON</p></li>
</ul>
<h2>Writing kernels and device functions</h2>
<p>As for CUDA kernels you can write templated and non-templated CUDA kernels.
Declaring a kernel function and launching it is straight forward:</p>
<pre class="c++"><code>spmd_kernel_1d(kernel_name, arguments)
  // kernel code
spmd_kernel_end

int main() {

  spmd_launch_kernel_1d(kernel_name, bit_width, param,
                        vector_size, arguments);

  return 0;
}</code></pre>
<p>The <code>bit_width</code> argument indicates the types width in bits that will be
available inside kernels. The <code>param</code> argument indicates the unroll factor for
CPUs and the number of threads per block for GPUs. The <code>vector_size</code> argument
indicates the vectors length passed as arguments.</p>
<p>Device functions can also been implemented. They are functions that will
only run on the device. As for kernels, they have the same restrictions.</p>
<pre class="c++"><code>spmd_dev_func(k_float device_func, k_float a, k_float b)
  // Device function code
spmd_dev_func_end

spmd_kernel_1d(kernel, arguments)

  // ...

  spmd_call_dev_func(device_func, a, b);

  // ...

spmd_kernel_end</code></pre>
<p>The caveat with <code>spmd_dev_func</code> is that its first argument must be the return
type followed by the device function name.</p>
<p>It is also possible to write templated kernels. Due to C++ <code>__VA_ARGS__</code>
limitations the number of template argument is limited to one of kind
<code>typename</code>. If more types or integers are to be passed to device kernels or
functions they have to be boxed inside a struct.</p>
<pre class="c++"><code>struct mul_t {
  spmd_dev_func(static k_float dev_impl, k_float a, k_float b)
    return a * b;
  spmd_dev_func_end
};

struct add_t {
  spmd_dev_func(static k_float dev_impl, k_float a, k_float b)
    return a + b;
  spmd_dev_func_end
};

// Op is the template argument (typename Op in C++ code)
spmd_tmpl_dev_func(k_float trampoline, Op, k_float a, k_float b)
  return Op::template spmd_call_dev_func(dev_impl, a, b);
spmd_dev_func_end

// Op is the template argument (typename Op in C++ code)
spmd_tmpl_kernel_1d(tmpl_kernel, Op, arguments)

  // ...

  spmd_call_tmpl_dev_func(trampoline, Op, a, b);

  // ...

spmd_kernel_end

int main() {

  // Kernel call for addition
  spmd_launch_tmpl_kernel_1d(tmpl_kernel, add_t, 32, 1, N, arguments);

  // Kernel call for multiplication
  spmd_launch_tmpl_kernel_1d(tmpl_kernel, mul_t, 32, 1, N, arguments);

  return 0;
}</code></pre>
<h2>The NSIMD SPMD C++ DSL</h2>
<p>The DSL is of course constraint by C++ syntax and constructs. This implies
some strange syntax and the impossibility to use infix operator <code>=</code>.
For now (2020/05/16) the NSIMD SPMD DSL does only supports <code>if</code>&apos;s, while-loops
and <code>returns</code>. It seems that for-loops and do-while-loops cannot be nicely
proposed, i.e. with a nice syntax, the switch-case keywords cannot be
implemented with a good conformence to the semantic of their C++ counterparts.
Goto&apos;s also cannot be implemented properly.</p>
<h3>Variables types available in kernels and device functions</h3>
<p>The following self-explanatory variable types are available inside kernels
and devices functions:</p>
<ul>
<li><p><code>k_int</code> for signed integers</p></li>
<li><p><code>k_uint</code> for unsigned integers</p></li>
<li><p><code>k_float</code> for floatting point numbers</p></li>
<li><p><code>k_bool</code> for booleans</p></li>
</ul>
<p>As explained above the bit-width of the above types are determined by the
launch kernel function. Note that <code>k_float</code> does not exists for 8-bits types.</p>
<h3>Load/store from/to memory</h3>
<p>Given a pointer, the proper way to load data is to use <code>k_load(ptr)</code>. For
storing a value to memory <code>k_store</code> is to be used.</p>
<pre class="c++"><code>k_store(ptr, value);
k_store(ptr, expression);</code></pre>
<p>As explained above, there is no need to compute the offset to apply to
pointers. This is hidden from the programmer.</p>
<h3>Assignment operator (<code>operator=</code>)</h3>
<p>Due to C++ ADL (<a href="https://en.cppreference.com/w/cpp/language/adl">https://en.cppreference.com/w/cpp/language/adl</a>) and the
need for keeping things simple for the compiler (which does not always mean
simple for the programmer) the use of infix operator <code>=</code> will not produce
a copmilation error but will give incorrect result. You should use <code>k_set</code>.</p>
<pre class="c++"><code>k_set(var, value);
k_set(var, expression);</code></pre>
<p>As written above, <code>k_set</code> assign value or the result of an expression to a
variable.</p>
<h3>if, then, else</h3>
<p>You should not use plan C++ <code>if</code>&apos;s or <code>else</code>&apos;s. This will not cause compilation
error but will produce incorrect results at runtime. You should use <code>k_if</code>,
<code>k_else</code>, <code>k_elseif</code> and <code>k_endif</code> instead. they have the same semantic as
their C++ counterparts.</p>
<pre class="c++"><code>spmd_kernel_1d(if_elseif_else, float *dst, float *a_ptr)

  k_float a, ret;
  k_set(a, k_load(a_ptr));

  k_if (a &gt; 15.0f)

    k_set(ret, 15.0f);

  k_elseif ( a &gt; 10.0f)

    k_set(ret, 10.0f);

  k_elseif ( a &gt; 5.0f)

    k_set(ret, 5.0f);

  k_else

    k_set(ret, 0.0f);

  k_endif

  k_store(dst, ret);

spmd_kernel_end</code></pre>
<h3>while loops</h3>
<p>You should not use plan C++ <code>while</code>&apos;s, <code>break</code>&apos;s and <code>continue</code>&apos;s. This will
not cause compilation error but will produce incorrect results at runtime.
You should use <code>k_while</code>, <code>k_break</code>, <code>k_continue</code> and <code>k_endif</code> instead. They
have the same semantic as their C++ counterparts.</p>
<pre class="c++"><code>spmd_kernel_1d(binpow, float *dst, float *a_ptr, int *p_ptr)

  k_float a, ret;
  k_set(a, k_load(a_ptr));
  k_set(ret, 1.0f);
  k_int p;
  k_set(p, k_load(p_ptr));

  k_while(p &gt; 0)

    k_if ((p &amp; 1) != 0)

      k_set(ret, ret * a);

    k_endif

    k_set(a, a * a);
    k_set(p, p &gt;&gt; 1);

  k_endwhile

  k_store(dst, ret);

spmd_kernel_end</code></pre>
<h3>Returns</h3>
<p>Returns cannot be implemented as macros overloading is not possible in a
standard way with an overload taking zero arguments. So returning has to be
done correctly. The <code>k_return</code> keyword has the same semantic as the C++
<code>return</code> keyword without arguments and can be used at will for kernels (as
kernels return type is always <code>void</code>) and for device functions returning
<code>void</code>.</p>
<p>For device functions returning a value it is recommanded to proceed this way:</p>
<ol>
<li><p>Declare a variable, say <code>ret</code>, to store the return value.</p></li>
<li><p>Whereever you need to return, set the variable appropriately with <code>k_set</code>
and return with <code>k_return</code>.</p></li>
<li><p>At the end of the function use <code>return ret;</code>.</p></li>
</ol>
<pre class="c++"><code>spmd_dev_func(k_int func, k_int a)

  k_float ret;

  k_if (a == 0)
    k_set(ret, 0);
    k_return;
  k_endif

  k_if (a == 1)
    k_set(ret, -1);
    k_return;
  k_endif

  k_set(ret, a);

  return ret;

spmd_dev_func_end</code></pre>
<h2>Advanced techniques and functions</h2>
<p>This paragraph applies mainly when targeting CPUs. Using techniques described
below won&apos;t affect GPUs.</p>
<p>If you are familiar with the SIMD technique of masking to emulate loops and
if&apos;s you may know that <code>k_set</code> and <code>k_store</code> are implemented using respectively
<code>nsimd::if_else</code> and <code>nsimd::maskz_storeu</code> which may incur performance
penalties. When you know that a simple assignment or store is sufficient
you may use the unmasked variants:</p>
<ul>
<li><p><code>k_unmasked_set</code> translates into a C++ assignment.</p></li>
<li><p><code>k_unmasked_store</code> translates into a C++ SIMD store.</p></li>
</ul>
<p>Their arguments are exactly the same as <code>k_set</code> and <code>k_store</code>. Unmasked
operations can usually be used at the beginning of device functions and also
inside loops, on temporary variables, knowing that the result of the latter
won&apos;t be needed later.</p>
<p>You may also use C++ standard keywords and constructs. But be aware that doing
so will apply all the same treatment too all SIMD lanes. This can be useful
when the operations involved are independant of the processed data as in the
example below.</p>
<pre class="c++"><code>spmd_dev_func(k_float newton_raphson_sqrt, k_float a, k_float x0)
  k_float ret;
  for (int i = 0; i &lt; 6; i++) {
    k_unmasked_set(ret, (ret + ret * a) / 2.0f);
  }
  return ret;
spmd_dev_func_end</code></pre>
  </body>
</html>
